"""
DecayingCosineAnnealingWarmRestarts å¿«é€ŸéªŒè¯è„šæœ¬
é€‚ç”¨äº runpod æˆ–ä»»ä½•ç¯å¢ƒ
"""
import math
from toolkit.scheduler import DecayingCosineAnnealingWarmRestarts
import torch

# åˆ›å»ºç®€å•çš„æ¨¡å‹å’Œä¼˜åŒ–å™¨
class SimpleModel(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.param = torch.nn.Parameter(torch.tensor(0.0))

def create_optimizer(lr):
    model = SimpleModel()
    return torch.optim.SGD(model.parameters(), lr=lr)

def test_basic():
    """åŸºç¡€åŠŸèƒ½æµ‹è¯•"""
    print("=" * 70)
    print("æµ‹è¯• 1: åŸºç¡€åŠŸèƒ½éªŒè¯")
    print("=" * 70)
    
    initial_lr = 1e-4
    T_0 = 100
    T_mult = 2
    eta_min = 1e-7
    restart_decay = 0.8
    total_steps = 700
    
    print(f"\né…ç½®: lr={initial_lr:.2e}, T_0={T_0}, T_mult={T_mult}, restart_decay={restart_decay}")
    
    opt = create_optimizer(initial_lr)
    sch = DecayingCosineAnnealingWarmRestarts(
        opt, T_0=T_0, T_mult=T_mult, eta_min=eta_min, restart_decay=restart_decay
    )
    
    lrs = []
    for i in range(total_steps):
        sch.step()
        lrs.append(opt.param_groups[0]['lr'])
    
    # æ£€æµ‹ restart ç‚¹
    jumps = [i for i in range(1, len(lrs)) if lrs[i] - lrs[i-1] > 1e-7]
    
    print(f"\næ£€æµ‹åˆ° {len(jumps)} ä¸ª restart ç‚¹: {jumps}")
    
    # æ£€æŸ¥æ¯ä¸ª restart çš„å­¦ä¹ ç‡
    restart_lrs = [initial_lr]
    print(f"\nRestart å­¦ä¹ ç‡éªŒè¯:")
    for idx, restart_step in enumerate(jumps):
        if restart_step < len(lrs):
            actual_lr = lrs[restart_step]
            expected_lr = initial_lr * (restart_decay ** (idx + 1))
            error = abs(actual_lr - expected_lr) / expected_lr
            status = "âœ“" if error < 0.01 else "âœ—"
            print(f"  Restart {idx+1} (step {restart_step}): {actual_lr:.6e} (æœŸæœ›: {expected_lr:.6e}) {status}")
            restart_lrs.append(actual_lr)
    
    print(f"\nå­¦ä¹ ç‡èŒƒå›´: {min(lrs):.2e} ~ {max(lrs):.2e}")
    
    return len(jumps) >= 2 and all(abs(restart_lrs[i+1]/restart_lrs[i] - restart_decay) < 0.01 for i in range(len(restart_lrs)-1))

def test_pytorch_compatibility():
    """ä¸ PyTorch åŸç”Ÿè°ƒåº¦å™¨å¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: PyTorch å…¼å®¹æ€§ (restart_decay=1.0)")
    print("=" * 70)
    
    initial_lr = 1e-4
    T_0 = 100
    T_mult = 2
    eta_min = 1e-7
    
    # PyTorch åŸç”Ÿ
    opt1 = create_optimizer(initial_lr)
    sch1 = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        opt1, T_0=T_0, T_mult=T_mult, eta_min=eta_min
    )
    
    # æˆ‘ä»¬çš„å®ç° (restart_decay=1.0)
    opt2 = create_optimizer(initial_lr)
    sch2 = DecayingCosineAnnealingWarmRestarts(
        opt2, T_0=T_0, T_mult=T_mult, eta_min=eta_min, restart_decay=1.0
    )
    
    max_diff = 0
    for i in range(300):
        sch1.step()
        sch2.step()
        diff = abs(opt1.param_groups[0]['lr'] - opt2.param_groups[0]['lr'])
        max_diff = max(max_diff, diff)
    
    print(f"\næœ€å¤§å·®å¼‚: {max_diff:.2e}")
    
    if max_diff < 1e-10:
        print("âœ“ PASS - ä¸ PyTorch å®Œå…¨ä¸€è‡´")
        return True
    else:
        print("âœ— FAIL - ä¸ PyTorch å­˜åœ¨å·®å¼‚")
        return False

def test_restart_decay():
    """æµ‹è¯•ä¸åŒ restart_decay å€¼"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: ä¸åŒ restart_decay å‚æ•°")
    print("=" * 70)
    
    initial_lr = 1e-4
    T_0 = 50
    
    for decay in [1.0, 0.8, 0.5]:
        print(f"\nrestart_decay={decay}:")
        opt = create_optimizer(initial_lr)
        sch = DecayingCosineAnnealingWarmRestarts(
            opt, T_0=T_0, T_mult=1, eta_min=1e-7, restart_decay=decay
        )
        
        lrs = []
        for i in range(250):
            sch.step()
            lrs.append(opt.param_groups[0]['lr'])
        
        jumps = [i for i in range(1, len(lrs)) if lrs[i] - lrs[i-1] > 1e-7]
        
        if len(jumps) >= 2:
            first_restart_lr = lrs[jumps[0]]
            second_restart_lr = lrs[jumps[1]]
            actual_decay = second_restart_lr / first_restart_lr
            print(f"  ç¬¬1æ¬¡ restart: {first_restart_lr:.6e}")
            print(f"  ç¬¬2æ¬¡ restart: {second_restart_lr:.6e}")
            print(f"  å®é™…è¡°å‡: {actual_decay:.4f} (æœŸæœ›: {decay})")
            if abs(actual_decay - decay) < 0.01:
                print(f"  âœ“ PASS")
            else:
                print(f"  âœ— FAIL")

def test_cosine_shape():
    """æµ‹è¯• cosine æ›²çº¿å½¢çŠ¶"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: Cosine æ›²çº¿å½¢çŠ¶")
    print("=" * 70)
    
    T_0 = 100
    opt = create_optimizer(1e-4)
    sch = DecayingCosineAnnealingWarmRestarts(
        opt, T_0=T_0, T_mult=1, eta_min=1e-7, restart_decay=0.8
    )
    
    lrs = []
    for i in range(T_0):
        sch.step()
        lrs.append(opt.param_groups[0]['lr'])
    
    print(f"\nç¬¬ä¸€ä¸ªå‘¨æœŸ (0-{T_0}):")
    print(f"  èµ·å§‹ LR: {lrs[0]:.6e}")
    print(f"  ä¸­ç‚¹ LR: {lrs[T_0//2]:.6e}")
    print(f"  ç»“æŸ LR: {lrs[-1]:.6e}")
    
    # Cosine æ›²çº¿åº”è¯¥å•è°ƒé€’å‡
    is_decreasing = all(lrs[i] >= lrs[i+1] for i in range(len(lrs)-1))
    
    if is_decreasing and lrs[0] > lrs[T_0//2] > lrs[-1]:
        print("  âœ“ PASS - Cosine æ›²çº¿å½¢çŠ¶æ­£ç¡®")
        return True
    else:
        print("  âœ— FAIL - Cosine æ›²çº¿å½¢çŠ¶ä¸æ­£ç¡®")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸ”" * 35)
    print("DecayingCosineAnnealingWarmRestarts éªŒè¯")
    print("ğŸ”" * 35 + "\n")
    
    results = []
    
    try:
        results.append(("åŸºç¡€åŠŸèƒ½", test_basic()))
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        results.append(("åŸºç¡€åŠŸèƒ½", False))
    
    try:
        results.append(("PyTorchå…¼å®¹æ€§", test_pytorch_compatibility()))
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        results.append(("PyTorchå…¼å®¹æ€§", False))
    
    try:
        test_restart_decay()
        results.append(("Restartè¡°å‡", True))
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        results.append(("Restartè¡°å‡", False))
    
    try:
        results.append(("Cosineå½¢çŠ¶", test_cosine_shape()))
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        results.append(("Cosineå½¢çŠ¶", False))
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"  {name}: {status}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! DecayingCosineAnnealingWarmRestarts å·¥ä½œæ­£å¸¸!")
        return 0
    else:
        print(f"\nâš  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit(main())
